{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97455922",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5884c9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ae487a",
   "metadata": {},
   "source": [
    "## 2. Generate Synthetic Demand Data\n",
    "\n",
    "Creating realistic logistics demand data with seasonal patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b194a69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Generate 2 years of daily demand data\n",
    "start_date = datetime(2022, 1, 1)\n",
    "n_days = 730  # 2 years\n",
    "\n",
    "dates = [start_date + timedelta(days=i) for i in range(n_days)]\n",
    "\n",
    "# Base demand with trend\n",
    "base_demand = 100 + np.arange(n_days) * 0.05  # Slight upward trend\n",
    "\n",
    "# Weekly seasonality (lower on weekends)\n",
    "weekly_pattern = np.array([1.2, 1.3, 1.2, 1.1, 1.0, 0.6, 0.5])  # Mon-Sun\n",
    "weekly_seasonality = np.array([weekly_pattern[d.weekday()] for d in dates])\n",
    "\n",
    "# Monthly seasonality (higher in Q4, lower in Q1)\n",
    "monthly_pattern = {\n",
    "    1: 0.85, 2: 0.88, 3: 0.95, 4: 1.0, 5: 1.05, 6: 1.08,\n",
    "    7: 1.02, 8: 1.0, 9: 1.1, 10: 1.15, 11: 1.25, 12: 1.35\n",
    "}\n",
    "monthly_seasonality = np.array([monthly_pattern[d.month] for d in dates])\n",
    "\n",
    "# Holiday effects (simplified)\n",
    "holiday_effect = np.ones(n_days)\n",
    "for i, d in enumerate(dates):\n",
    "    # Diwali period (Oct-Nov boost)\n",
    "    if d.month == 10 and d.day >= 20:\n",
    "        holiday_effect[i] = 1.5\n",
    "    elif d.month == 11 and d.day <= 15:\n",
    "        holiday_effect[i] = 1.6\n",
    "    # Year end boost\n",
    "    elif d.month == 12 and d.day >= 15:\n",
    "        holiday_effect[i] = 1.4\n",
    "\n",
    "# Combine all factors\n",
    "demand = base_demand * weekly_seasonality * monthly_seasonality * holiday_effect\n",
    "\n",
    "# Add noise\n",
    "noise = np.random.normal(0, 10, n_days)\n",
    "demand = np.maximum(demand + noise, 10)  # Ensure positive demand\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'date': dates,\n",
    "    'demand': demand.astype(int),\n",
    "    'day_of_week': [d.weekday() for d in dates],\n",
    "    'day_of_month': [d.day for d in dates],\n",
    "    'month': [d.month for d in dates],\n",
    "    'year': [d.year for d in dates],\n",
    "    'quarter': [(d.month - 1) // 3 + 1 for d in dates],\n",
    "    'is_weekend': [1 if d.weekday() >= 5 else 0 for d in dates],\n",
    "    'week_of_year': [d.isocalendar()[1] for d in dates]\n",
    "})\n",
    "\n",
    "# Add region dimension\n",
    "regions = ['North', 'South', 'East', 'West', 'Central']\n",
    "region_weights = [1.0, 1.2, 0.9, 1.1, 0.8]\n",
    "\n",
    "demand_data = []\n",
    "for i, region in enumerate(regions):\n",
    "    region_df = df.copy()\n",
    "    region_df['region'] = region\n",
    "    region_df['demand'] = (region_df['demand'] * region_weights[i] + \n",
    "                           np.random.normal(0, 5, len(region_df))).astype(int)\n",
    "    demand_data.append(region_df)\n",
    "\n",
    "df_full = pd.concat(demand_data, ignore_index=True)\n",
    "df_full['demand'] = np.maximum(df_full['demand'], 1)\n",
    "\n",
    "print(f\"Dataset shape: {df_full.shape}\")\n",
    "print(f\"\\nDate range: {df_full['date'].min()} to {df_full['date'].max()}\")\n",
    "print(f\"\\nRegions: {df_full['region'].unique()}\")\n",
    "print(f\"\\nSample data:\")\n",
    "df_full.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4597ce",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65b166a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"üìä Demand Statistics by Region:\\n\")\n",
    "region_stats = df_full.groupby('region')['demand'].agg(['mean', 'std', 'min', 'max'])\n",
    "region_stats.columns = ['Mean', 'Std Dev', 'Min', 'Max']\n",
    "print(region_stats.round(2))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nüìä Demand Statistics by Day of Week:\\n\")\n",
    "dow_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "dow_stats = df_full.groupby('day_of_week')['demand'].mean()\n",
    "for i, (dow, val) in enumerate(dow_stats.items()):\n",
    "    print(f\"   {dow_names[dow]}: {val:.1f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nüìä Demand Statistics by Month:\\n\")\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "               'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "month_stats = df_full.groupby('month')['demand'].mean()\n",
    "for month, val in month_stats.items():\n",
    "    print(f\"   {month_names[month-1]}: {val:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a936bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series visualization\n",
    "fig, axes = plt.subplots(3, 2, figsize=(16, 14))\n",
    "\n",
    "# 1. Overall demand trend\n",
    "ax1 = axes[0, 0]\n",
    "daily_total = df_full.groupby('date')['demand'].sum().reset_index()\n",
    "ax1.plot(daily_total['date'], daily_total['demand'], alpha=0.7, linewidth=0.5)\n",
    "# Add rolling average\n",
    "rolling_avg = daily_total['demand'].rolling(window=30).mean()\n",
    "ax1.plot(daily_total['date'], rolling_avg, color='red', linewidth=2, label='30-day MA')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Total Daily Demand')\n",
    "ax1.set_title('Overall Demand Trend', fontsize=14, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Demand by region\n",
    "ax2 = axes[0, 1]\n",
    "for region in regions:\n",
    "    region_data = df_full[df_full['region'] == region].groupby('date')['demand'].sum()\n",
    "    rolling = region_data.rolling(window=30).mean()\n",
    "    ax2.plot(rolling.index, rolling.values, label=region, linewidth=1.5)\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_ylabel('Demand')\n",
    "ax2.set_title('Demand by Region (30-day MA)', fontsize=14, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Weekly pattern\n",
    "ax3 = axes[1, 0]\n",
    "weekly_avg = df_full.groupby('day_of_week')['demand'].mean()\n",
    "colors = ['#2ecc71' if x < 5 else '#e74c3c' for x in range(7)]\n",
    "bars = ax3.bar(dow_names, weekly_avg.values, color=colors, edgecolor='black')\n",
    "ax3.set_xlabel('Day of Week')\n",
    "ax3.set_ylabel('Average Demand')\n",
    "ax3.set_title('Weekly Demand Pattern', fontsize=14, fontweight='bold')\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 4. Monthly pattern\n",
    "ax4 = axes[1, 1]\n",
    "monthly_avg = df_full.groupby('month')['demand'].mean()\n",
    "colors = plt.cm.RdYlGn(np.linspace(0.2, 0.8, 12))\n",
    "ax4.bar(month_names, monthly_avg.values, color=colors, edgecolor='black')\n",
    "ax4.set_xlabel('Month')\n",
    "ax4.set_ylabel('Average Demand')\n",
    "ax4.set_title('Monthly Demand Pattern', fontsize=14, fontweight='bold')\n",
    "ax4.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 5. Region comparison boxplot\n",
    "ax5 = axes[2, 0]\n",
    "df_full.boxplot(column='demand', by='region', ax=ax5)\n",
    "ax5.set_xlabel('Region')\n",
    "ax5.set_ylabel('Demand')\n",
    "ax5.set_title('Demand Distribution by Region', fontsize=14, fontweight='bold')\n",
    "plt.suptitle('')  # Remove automatic title\n",
    "\n",
    "# 6. Year-over-year comparison\n",
    "ax6 = axes[2, 1]\n",
    "for year in df_full['year'].unique():\n",
    "    year_data = df_full[df_full['year'] == year].groupby('month')['demand'].mean()\n",
    "    ax6.plot(month_names[:len(year_data)], year_data.values, marker='o', label=str(year), linewidth=2)\n",
    "ax6.set_xlabel('Month')\n",
    "ax6.set_ylabel('Average Demand')\n",
    "ax6.set_title('Year-over-Year Comparison', fontsize=14, fontweight='bold')\n",
    "ax6.legend()\n",
    "ax6.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/demand_eda_plots.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìà EDA plots saved to '../data/demand_eda_plots.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6172813",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering for Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d48808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate to daily level for forecasting\n",
    "daily_demand = df_full.groupby(['date', 'region']).agg({\n",
    "    'demand': 'sum',\n",
    "    'day_of_week': 'first',\n",
    "    'day_of_month': 'first',\n",
    "    'month': 'first',\n",
    "    'year': 'first',\n",
    "    'quarter': 'first',\n",
    "    'is_weekend': 'first',\n",
    "    'week_of_year': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Create lag features\n",
    "for lag in [1, 7, 14, 28]:\n",
    "    daily_demand[f'demand_lag_{lag}'] = daily_demand.groupby('region')['demand'].shift(lag)\n",
    "\n",
    "# Rolling statistics\n",
    "for window in [7, 14, 30]:\n",
    "    daily_demand[f'demand_rolling_mean_{window}'] = (\n",
    "        daily_demand.groupby('region')['demand']\n",
    "        .transform(lambda x: x.rolling(window=window, min_periods=1).mean())\n",
    "    )\n",
    "    daily_demand[f'demand_rolling_std_{window}'] = (\n",
    "        daily_demand.groupby('region')['demand']\n",
    "        .transform(lambda x: x.rolling(window=window, min_periods=1).std())\n",
    "    )\n",
    "\n",
    "# Cyclical encoding for time features\n",
    "daily_demand['day_sin'] = np.sin(2 * np.pi * daily_demand['day_of_week'] / 7)\n",
    "daily_demand['day_cos'] = np.cos(2 * np.pi * daily_demand['day_of_week'] / 7)\n",
    "daily_demand['month_sin'] = np.sin(2 * np.pi * daily_demand['month'] / 12)\n",
    "daily_demand['month_cos'] = np.cos(2 * np.pi * daily_demand['month'] / 12)\n",
    "\n",
    "# One-hot encode region\n",
    "region_dummies = pd.get_dummies(daily_demand['region'], prefix='region')\n",
    "daily_demand = pd.concat([daily_demand, region_dummies], axis=1)\n",
    "\n",
    "# Drop rows with NaN (due to lag features)\n",
    "daily_demand = daily_demand.dropna()\n",
    "\n",
    "print(f\"Feature-engineered dataset shape: {daily_demand.shape}\")\n",
    "print(f\"\\nFeatures created:\")\n",
    "print(daily_demand.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66000077",
   "metadata": {},
   "source": [
    "## 5. Train-Test Split (Time-Based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebc2fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based split (last 60 days for testing)\n",
    "split_date = daily_demand['date'].max() - timedelta(days=60)\n",
    "\n",
    "train_data = daily_demand[daily_demand['date'] <= split_date].copy()\n",
    "test_data = daily_demand[daily_demand['date'] > split_date].copy()\n",
    "\n",
    "# Feature columns\n",
    "feature_cols = [\n",
    "    'day_of_week', 'day_of_month', 'month', 'quarter', 'is_weekend', 'week_of_year',\n",
    "    'demand_lag_1', 'demand_lag_7', 'demand_lag_14', 'demand_lag_28',\n",
    "    'demand_rolling_mean_7', 'demand_rolling_mean_14', 'demand_rolling_mean_30',\n",
    "    'demand_rolling_std_7', 'demand_rolling_std_14', 'demand_rolling_std_30',\n",
    "    'day_sin', 'day_cos', 'month_sin', 'month_cos'\n",
    "] + [col for col in daily_demand.columns if col.startswith('region_')]\n",
    "\n",
    "X_train = train_data[feature_cols]\n",
    "y_train = train_data['demand']\n",
    "X_test = test_data[feature_cols]\n",
    "y_test = test_data['demand']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "print(f\"Features: {len(feature_cols)}\")\n",
    "print(f\"\\nTraining period: {train_data['date'].min()} to {train_data['date'].max()}\")\n",
    "print(f\"Test period: {test_data['date'].min()} to {test_data['date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb80d83e",
   "metadata": {},
   "source": [
    "## 6. Model Training and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a495202f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "import time\n",
    "\n",
    "# Define models to compare\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42),\n",
    "    'AdaBoost': AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"Training and evaluating models...\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for name, model in models.items():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "    \n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2,\n",
    "        'MAPE': mape,\n",
    "        'Train Time (s)': train_time\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"   MAE:  {mae:.2f}\")\n",
    "    print(f\"   RMSE: {rmse:.2f}\")\n",
    "    print(f\"   R¬≤:   {r2:.4f}\")\n",
    "    print(f\"   MAPE: {mape:.2f}%\")\n",
    "    print(f\"   Time: {train_time:.2f}s\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c50f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results comparison\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('R2', ascending=False)\n",
    "\n",
    "print(\"\\nüìä Model Comparison Summary:\\n\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "metrics = ['MAE', 'RMSE', 'R2', 'MAPE']\n",
    "titles = ['Mean Absolute Error (lower is better)', \n",
    "          'Root Mean Squared Error (lower is better)',\n",
    "          'R¬≤ Score (higher is better)', \n",
    "          'Mean Absolute % Error (lower is better)']\n",
    "\n",
    "for ax, metric, title in zip(axes.flat, metrics, titles):\n",
    "    colors = ['#2ecc71' if metric == 'R2' else '#3498db'] * len(results_df)\n",
    "    if metric == 'R2':\n",
    "        best_idx = results_df[metric].idxmax()\n",
    "    else:\n",
    "        best_idx = results_df[metric].idxmin()\n",
    "    colors[list(results_df.index).index(best_idx)] = '#e74c3c'\n",
    "    \n",
    "    bars = ax.barh(results_df['Model'], results_df[metric], color=colors, edgecolor='black')\n",
    "    ax.set_xlabel(metric)\n",
    "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "    ax.grid(True, axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/demand_model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìà Model comparison plot saved to '../data/demand_model_comparison.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93f701d",
   "metadata": {},
   "source": [
    "## 7. Best Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b24d0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best model (Random Forest or highest R2)\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print(f\"üèÜ Best Model: {best_model_name}\")\n",
    "print(f\"   R¬≤ Score: {results_df.iloc[0]['R2']:.4f}\")\n",
    "\n",
    "# Get predictions\n",
    "y_pred_best = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Visualization of predictions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Actual vs Predicted time series\n",
    "ax1 = axes[0, 0]\n",
    "test_dates = test_data['date'].values\n",
    "ax1.plot(test_dates, y_test.values, label='Actual', alpha=0.8, linewidth=1)\n",
    "ax1.plot(test_dates, y_pred_best, label='Predicted', alpha=0.8, linewidth=1, linestyle='--')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Demand')\n",
    "ax1.set_title('Demand Forecast vs Actual', fontsize=14, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Scatter plot\n",
    "ax2 = axes[0, 1]\n",
    "ax2.scatter(y_test, y_pred_best, alpha=0.5, edgecolors='none')\n",
    "ax2.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "ax2.set_xlabel('Actual Demand')\n",
    "ax2.set_ylabel('Predicted Demand')\n",
    "ax2.set_title('Actual vs Predicted Scatter', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Residual distribution\n",
    "ax3 = axes[1, 0]\n",
    "residuals = y_test.values - y_pred_best\n",
    "ax3.hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "ax3.axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "ax3.set_xlabel('Residual (Actual - Predicted)')\n",
    "ax3.set_ylabel('Frequency')\n",
    "ax3.set_title('Residual Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 4. Prediction by region\n",
    "ax4 = axes[1, 1]\n",
    "test_data_with_pred = test_data.copy()\n",
    "test_data_with_pred['predicted'] = y_pred_best\n",
    "region_accuracy = test_data_with_pred.groupby('region').apply(\n",
    "    lambda x: r2_score(x['demand'], x['predicted'])\n",
    ")\n",
    "colors = plt.cm.RdYlGn(np.linspace(0.2, 0.8, len(region_accuracy)))\n",
    "ax4.bar(region_accuracy.index, region_accuracy.values, color=colors, edgecolor='black')\n",
    "ax4.set_xlabel('Region')\n",
    "ax4.set_ylabel('R¬≤ Score')\n",
    "ax4.set_title('Model Performance by Region', fontsize=14, fontweight='bold')\n",
    "ax4.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/demand_forecast_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìà Forecast analysis plots saved to '../data/demand_forecast_analysis.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63a45cc",
   "metadata": {},
   "source": [
    "## 8. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a336b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances (for tree-based models)\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"üîç Top 15 Most Important Features for Demand Forecasting:\\n\")\n",
    "    print(feature_importance.head(15).to_string(index=False))\n",
    "    \n",
    "    # Visualization\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    top_features = feature_importance.head(15)\n",
    "    colors = plt.cm.RdYlGn(np.linspace(0.2, 0.8, len(top_features)))\n",
    "    \n",
    "    bars = ax.barh(range(len(top_features)), top_features['importance'], color=colors)\n",
    "    ax.set_yticks(range(len(top_features)))\n",
    "    ax.set_yticklabels(top_features['feature'])\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel('Feature Importance')\n",
    "    ax.set_title(f'Top 15 Feature Importances ({best_model_name})', fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, axis='x', alpha=0.3)\n",
    "    \n",
    "    for bar, val in zip(bars, top_features['importance']):\n",
    "        ax.text(val + 0.005, bar.get_y() + bar.get_height()/2, f'{val:.3f}', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../data/demand_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüìä Feature importance plot saved to '../data/demand_feature_importance.png'\")\n",
    "else:\n",
    "    print(f\"Feature importances not available for {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd78a0e",
   "metadata": {},
   "source": [
    "## 9. Future Demand Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff2ad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate future dates for forecasting\n",
    "last_date = daily_demand['date'].max()\n",
    "forecast_days = 30\n",
    "future_dates = [last_date + timedelta(days=i+1) for i in range(forecast_days)]\n",
    "\n",
    "# Create future features (simplified - using last known values for lags)\n",
    "future_forecasts = []\n",
    "\n",
    "for region in regions:\n",
    "    region_data = daily_demand[daily_demand['region'] == region].copy()\n",
    "    last_row = region_data.iloc[-1]\n",
    "    \n",
    "    for i, future_date in enumerate(future_dates):\n",
    "        future_row = {\n",
    "            'date': future_date,\n",
    "            'region': region,\n",
    "            'day_of_week': future_date.weekday(),\n",
    "            'day_of_month': future_date.day,\n",
    "            'month': future_date.month,\n",
    "            'quarter': (future_date.month - 1) // 3 + 1,\n",
    "            'is_weekend': 1 if future_date.weekday() >= 5 else 0,\n",
    "            'week_of_year': future_date.isocalendar()[1],\n",
    "            'demand_lag_1': last_row['demand'],\n",
    "            'demand_lag_7': last_row['demand_lag_7'] if 'demand_lag_7' in last_row else last_row['demand'],\n",
    "            'demand_lag_14': last_row['demand_lag_14'] if 'demand_lag_14' in last_row else last_row['demand'],\n",
    "            'demand_lag_28': last_row['demand_lag_28'] if 'demand_lag_28' in last_row else last_row['demand'],\n",
    "            'demand_rolling_mean_7': last_row['demand_rolling_mean_7'],\n",
    "            'demand_rolling_mean_14': last_row['demand_rolling_mean_14'],\n",
    "            'demand_rolling_mean_30': last_row['demand_rolling_mean_30'],\n",
    "            'demand_rolling_std_7': last_row['demand_rolling_std_7'],\n",
    "            'demand_rolling_std_14': last_row['demand_rolling_std_14'],\n",
    "            'demand_rolling_std_30': last_row['demand_rolling_std_30'],\n",
    "            'day_sin': np.sin(2 * np.pi * future_date.weekday() / 7),\n",
    "            'day_cos': np.cos(2 * np.pi * future_date.weekday() / 7),\n",
    "            'month_sin': np.sin(2 * np.pi * future_date.month / 12),\n",
    "            'month_cos': np.cos(2 * np.pi * future_date.month / 12)\n",
    "        }\n",
    "        \n",
    "        # Add region dummies\n",
    "        for r in regions:\n",
    "            future_row[f'region_{r}'] = 1 if r == region else 0\n",
    "        \n",
    "        future_forecasts.append(future_row)\n",
    "\n",
    "future_df = pd.DataFrame(future_forecasts)\n",
    "X_future = future_df[feature_cols]\n",
    "X_future_scaled = scaler.transform(X_future)\n",
    "\n",
    "# Predict\n",
    "future_df['predicted_demand'] = best_model.predict(X_future_scaled)\n",
    "\n",
    "# Display forecast summary\n",
    "print(f\"üìÖ 30-Day Demand Forecast (Starting {future_dates[0].strftime('%Y-%m-%d')})\\n\")\n",
    "forecast_summary = future_df.groupby('region')['predicted_demand'].agg(['mean', 'sum'])\n",
    "forecast_summary.columns = ['Daily Average', 'Total (30 days)']\n",
    "print(forecast_summary.round(0))\n",
    "\n",
    "print(f\"\\nüìä Total Forecasted Demand: {future_df['predicted_demand'].sum():,.0f} shipments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c77a989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize forecast\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# 1. Forecast by region over time\n",
    "ax1 = axes[0]\n",
    "for region in regions:\n",
    "    region_forecast = future_df[future_df['region'] == region]\n",
    "    ax1.plot(region_forecast['date'], region_forecast['predicted_demand'], \n",
    "             marker='o', label=region, linewidth=2, markersize=4)\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Predicted Demand')\n",
    "ax1.set_title('30-Day Demand Forecast by Region', fontsize=14, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Total daily forecast\n",
    "ax2 = axes[1]\n",
    "daily_total_forecast = future_df.groupby('date')['predicted_demand'].sum()\n",
    "ax2.fill_between(daily_total_forecast.index, daily_total_forecast.values, alpha=0.3)\n",
    "ax2.plot(daily_total_forecast.index, daily_total_forecast.values, \n",
    "         marker='o', linewidth=2, markersize=6, color='#e74c3c')\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_ylabel('Total Predicted Demand')\n",
    "ax2.set_title('Total Daily Demand Forecast', fontsize=14, fontweight='bold')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/demand_forecast_30day.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìà Forecast visualization saved to '../data/demand_forecast_30day.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3722ff66",
   "metadata": {},
   "source": [
    "## 10. Save Model and Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7816ec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Create models directory\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model_path = '../models/demand_model_notebook.pkl'\n",
    "joblib.dump(best_model, model_path)\n",
    "print(f\"‚úÖ Model saved to: {model_path}\")\n",
    "\n",
    "# Save scaler\n",
    "scaler_path = '../models/demand_scaler_notebook.pkl'\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f\"‚úÖ Scaler saved to: {scaler_path}\")\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    'model_type': best_model_name,\n",
    "    'training_date': datetime.now().isoformat(),\n",
    "    'features': feature_cols,\n",
    "    'num_features': len(feature_cols),\n",
    "    'regions': regions,\n",
    "    'training_period': {\n",
    "        'start': train_data['date'].min().isoformat(),\n",
    "        'end': train_data['date'].max().isoformat()\n",
    "    },\n",
    "    'metrics': {\n",
    "        'mae': float(results_df.iloc[0]['MAE']),\n",
    "        'rmse': float(results_df.iloc[0]['RMSE']),\n",
    "        'r2': float(results_df.iloc[0]['R2']),\n",
    "        'mape': float(results_df.iloc[0]['MAPE'])\n",
    "    }\n",
    "}\n",
    "\n",
    "metadata_path = '../models/demand_model_metadata.json'\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2, default=str)\n",
    "print(f\"‚úÖ Metadata saved to: {metadata_path}\")\n",
    "\n",
    "# Save forecast data\n",
    "forecast_path = '../data/demand_forecast_30day.csv'\n",
    "future_df.to_csv(forecast_path, index=False)\n",
    "print(f\"‚úÖ Forecast data saved to: {forecast_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL ARTIFACTS SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"üìÅ Model:    {model_path}\")\n",
    "print(f\"üìÅ Scaler:   {scaler_path}\")\n",
    "print(f\"üìÅ Metadata: {metadata_path}\")\n",
    "print(f\"üìÅ Forecast: {forecast_path}\")\n",
    "print(f\"\\nüéØ Best Model: {best_model_name} (R¬≤ = {results_df.iloc[0]['R2']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66c17ce",
   "metadata": {},
   "source": [
    "## 11. Conclusions\n",
    "\n",
    "### Key Findings:\n",
    "1. **Lag features** (especially 1-day and 7-day lags) are most predictive\n",
    "2. **Rolling statistics** capture trend and volatility effectively\n",
    "3. Strong **weekly seasonality** with lower weekend demand\n",
    "4. **Monthly patterns** show Q4 peak (Diwali, year-end)\n",
    "5. **Regional variation** exists - South region has highest demand\n",
    "\n",
    "### Model Performance:\n",
    "- Tree-based models outperform linear models\n",
    "- Random Forest/Gradient Boosting achieve best R¬≤ scores\n",
    "- MAPE typically under 15% for practical forecasting\n",
    "\n",
    "### Recommendations:\n",
    "- Use 30-day forecasts for capacity planning\n",
    "- Monitor weekly patterns for staffing decisions\n",
    "- Prepare for Q4 surge with increased resources\n",
    "- Consider region-specific models for higher accuracy\n",
    "\n",
    "---\n",
    "*Notebook completed - Demand forecasting model ready for production*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
